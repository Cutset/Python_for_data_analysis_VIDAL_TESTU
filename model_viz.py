# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q-z3nxcmrK5iapr5AwoPVxxWThd7nqn4

Etape 1: Importation des donn√©es

Importation librairies
"""

import io
import base64
from numpy import load
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.widgets import Slider, Button
from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas
from matplotlib.figure import Figure
from flask import Flask, render_template
from sklearn.metrics import classification_report
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve
import pickle

def test_plot():
    # Generate plot
    fig = Figure()
    axis = fig.add_subplot(1, 1, 1)
    axis.set_title("title")
    axis.set_xlabel("x-axis")
    axis.set_ylabel("y-axis")
    axis.grid()
    axis.plot(range(5), range(5), "ro-")
    return fig_to_b64str(fig)
    

def fig_to_b64str(fig):
    # Convert plot to PNG image
    pngImage = io.BytesIO()
    FigureCanvas(fig).print_png(pngImage)
    
    # Encode PNG image to base64 string
    pngImageB64String = "data:image/png;base64,"
    pngImageB64String += base64.b64encode(pngImage.getvalue()).decode('utf8')
    return pngImageB64String

def roc(model, X_test, y_test):
    probs = model.predict_proba(X_test)
    probs = probs[:,1]

    auc = roc_auc_score(y_test, probs)
    print("AUROC = %.3f" % (auc))

    fpr, tpr, _ = roc_curve(y_test, probs)
    #plt.plot(fpr, tpr, marker=".", label="(AUROC = %0.3f)" % auc)

    fig = Figure()
    axis = fig.add_subplot(1, 1, 1)
    axis.set_title("AUROC = %.3f" % (auc))
    axis.set_xlabel("x-axis")
    axis.set_ylabel("y-axis")
    axis.plot(fpr, tpr, marker=".", label="(AUROC = %0.3f)" % auc)
    print(fig_to_b64str(fig))
    return fig_to_b64str(fig)

def viz(arg1, arg2, X_test, y_test): #arg1 is the model and arg2 is what we display
    fig = Figure()
    model = pickle.load(open(arg1, 'rb'))
    if arg2 == "Classification Report":
        cv = classification_report(y_test, model.predict(X_test), digits = 4, output_dict = True)
        f1score = f1_score(y_test, model.predict(X_test), average='weighted')
        #return render_template('classification_report.html', cv = cv, f1_score =f1score)
        return f"""
        <table class="table">
            <thead>
                <tr>
                    <th colspan="2">Classification report</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td></td>
                    <td>precision</td>
                    <td>recall</td>
                    <td>f1-score</td>
                    <td>support</td>
                </tr>
                <tr>
                    <td>0</td>
                    <td>{cv['0']['precision']}</td>
                    <td>{cv['0']['recall']}</td>
                    <td>{cv['0']['f1-score']}</td>
                    <td>{cv['0']['support']}</td>
                </tr>
                <tr>
                    <td>1</td>
                    <td>{cv['1']['precision']}</td>
                    <td>{cv['1']['recall']}</td>
                    <td>{cv['1']['f1-score']}</td>
                    <td>{cv['1']['support']}</td>
                </tr>
                <tr>
                    <td>weighted avg</td>
                    <td>{cv['weighted avg']['precision']}</td>
                    <td>{cv['weighted avg']['recall']}</td>
                    <td>{cv['weighted avg']['f1-score']}</td>
                    <td>{cv['weighted avg']['support']}</td>
                </tr>
            </tbody>
        </table>

        </hr>
        <h5> Accuracy : {cv['accuracy']}</h5>
        """
    elif arg2 == "Confusion matrix":
        cm = confusion_matrix(y_test, model.predict(X_test))
        return f"""
        <table class="table">
            <thead>
                <tr>
                    <th colspan="2">Confusion matrix</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td></td>
                    <td>0</td>
                    <td>1</td>
                </tr>
                <tr>
                    <td>0</td>
                    <td>{cm[0][0]}</td>
                    <td>{cm[0][1]}</td>
                </tr>
                <tr>
                    <td>1</td>
                    <td>{cm[1][0]}</td>
                    <td>{cm[1][1]}</td>
                </tr>
              </tbody>
        </table>
        """
    else :
        return roc(model, X_test, y_test)